import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from Decoder import DW_Tracer, DW_Detector
from Noise_Layer import RandomForwardNoisePool

# ì„¤ì • ë³€ìˆ˜ë“¤
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MESSAGE_LENGTH = 128
INPUT_RESIZE = 256
BATCH_SIZE = 32   #32
LEARNING_RATE = 1e-4
EPOCHS = 5
SAVE_INTERVAL = 10
VAL_SPLIT = 0.8
TRACER_MODEL_PATH = "./saved_models/tracer_model.pth"
DETECTOR_MODEL_PATH = "./saved_models/detector_model.pth"
RESULTS_DIR = "./results"
MAX_SAMPLES = 1000   # ìµœëŒ€ 100ê°œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©



# ê²½ë¡œ ë° ë””ë ‰í„°ë¦¬ ì„¤ì •
ENCODED_DIR = "../test_output_encoded_val_128"  # ì›Œí„°ë§ˆí¬ê°€ ì‚½ì…ëœ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
ORIGINAL_DIR = "../dataset/val_128"              # ì›ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
os.makedirs("./saved_models", exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)

# ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜ (Encoder_main.pyì™€ ë™ì¼í•˜ê²Œ ë©”ì‹œì§€ ìƒì„±)
def make_fixed_message(text, length):
    text_bytes = text.encode('utf-8')
    text_tensor = torch.tensor(list(text_bytes), dtype=torch.float32)

    if text_tensor.numel() >= length:
        message = text_tensor[:length]
    else:
        pad_size = length - text_tensor.numel()
        message = torch.cat([text_tensor, torch.zeros(pad_size)], dim=0)

    # -0.1~0.1 ë²”ìœ„ë¡œ ì •ê·œí™”
    message = (message - 128) / 128 * 0.2
    return message

# ê³ ì • ë©”ì‹œì§€ ë¬¸ìì—´ ë° í…ì„œ ì„¤ì •
FIXED_MESSAGE_STR = "hello world"
fixed_message = make_fixed_message(FIXED_MESSAGE_STR, MESSAGE_LENGTH)

# ì •í™•ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_bit_accuracy(pred, target, threshold=0):
    # ì´ì§„ ë©”ì‹œì§€ë¡œ ë³€í™˜ (-0.1~0.1 ë²”ìœ„ â†’ 0 ë˜ëŠ” 1)
    pred_binary = (pred > threshold).float()
    target_binary = (target > threshold).float()
    
    # ì •í™•ë„ ê³„ì‚° (ì •í™•íˆ ë§ì¶˜ ë¹„íŠ¸ / ì „ì²´ ë¹„íŠ¸)
    accuracy = (pred_binary == target_binary).float().mean().item()
    return accuracy * 100  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜

# ì›Œí„°ë§ˆí¬ëœ ì´ë¯¸ì§€ ë°ì´í„°ì…‹
class WatermarkedImageDataset(Dataset):
    def __init__(self, encoded_dir, original_dir, message, transform=None):
        print(f"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
        print(f"íƒ€ê²Ÿ ë””ë ‰í† ë¦¬: {os.path.abspath(ENCODED_DIR)}")

        # ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¡œë“œ
        encoded_files = [f for f in os.listdir(encoded_dir) if f.endswith('.png')]
        self.encoded_paths = sorted([os.path.join(encoded_dir, f) for f in encoded_files])
        print(f"ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ê°œìˆ˜: {len(self.encoded_paths)}")
        
        # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ë¡œë“œ - ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ì´ë¦„ì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œí•˜ì—¬ ë§¤í•‘
        self.original_paths = []
        for encoded_file in encoded_files:
            # 'encoded_00001.png'ì—ì„œ '00001' ì¶”ì¶œ
            if 'encoded_' in encoded_file:
                number_part = encoded_file.replace('encoded_', '').split('.')[0]
                original_file = f"{number_part}.png"  # '00001.png' í˜•ì‹
            else:
                # ë‹¤ë¥¸ íŒ¨í„´ì˜ ê²½ìš° ì²˜ë¦¬
                original_file = encoded_file
                
            original_path = os.path.join(original_dir, original_file)
            if os.path.exists(original_path):
                self.original_paths.append(original_path)
            else:
                print(f"âš ï¸ ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {original_file}")
        
        # ë§¤ì¹­ëœ íŒŒì¼ë§Œ ìœ ì§€
        if len(self.original_paths) < len(self.encoded_paths):
            print(f"âš ï¸ ì›ë³¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ì¸ì½”ë”© ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ë§¤ì¹­ëœ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # ë§¤ì¹­ëœ ì¸ì½”ë”© ì´ë¯¸ì§€ ê²½ë¡œë§Œ ìœ ì§€
            matched_indices = [i for i, path in enumerate(self.encoded_paths) 
                            if i < len(self.original_paths)]
            self.encoded_paths = [self.encoded_paths[i] for i in matched_indices]
        
        print(f"ë§¤ì¹­ëœ ì´ë¯¸ì§€ ìŒ ê°œìˆ˜: {len(self.encoded_paths)}")
        
        # ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ
        if MAX_SAMPLES > 0 and MAX_SAMPLES < len(self.encoded_paths):
            print(f"âš ï¸ ë°ì´í„°ì…‹ì„ {MAX_SAMPLES}ê°œë¡œ ì œí•œí•©ë‹ˆë‹¤")
            self.encoded_paths = self.encoded_paths[:MAX_SAMPLES]
            self.original_paths = self.original_paths[:MAX_SAMPLES]
        
        print(f"ì‚¬ìš©í•  ì´ë¯¸ì§€ ê°œìˆ˜: {len(self.encoded_paths)}")
        self.message = message
        self.transform = transform or transforms.Compose([
            transforms.Resize((INPUT_RESIZE, INPUT_RESIZE)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
        
    def __len__(self):
        return len(self.encoded_paths)
    
    def __getitem__(self, idx):
        if idx >= len(self.encoded_paths):
            idx = idx % len(self.encoded_paths)
            
        try:
            encoded_img = Image.open(self.encoded_paths[idx]).convert('RGB')
            original_img = Image.open(self.original_paths[idx]).convert('RGB')
            
            if self.transform:
                encoded_img = self.transform(encoded_img)
                original_img = self.transform(original_img)
                
            return encoded_img, original_img, self.message
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë”© ì˜¤ë¥˜ (idx={idx}): {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ë°˜í™˜ (ì•ˆì „ ì¡°ì¹˜)
            return self.__getitem__(0)


# í•™ìŠµ í•¨ìˆ˜
def train_decoder(model_type='tracer'):
    print(f"\n{'='*50}")
    print(f"[{model_type.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘]")
    print(f"{'='*50}")
    
    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì„¤ì •
    print("1. ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    dataset = WatermarkedImageDataset(ENCODED_DIR, ORIGINAL_DIR, fixed_message)
    
    train_size = int(VAL_SPLIT * len(dataset))
    val_size = len(dataset) - train_size
    print(f"2. ë°ì´í„°ì…‹ ë¶„í• : í•™ìŠµ={train_size}ê°œ, ê²€ì¦={val_size}ê°œ")
    
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    print(f"3. ë°ì´í„°ë¡œë” ì´ˆê¸°í™”: ë°°ì¹˜ í¬ê¸°={BATCH_SIZE}")
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
    
    print(f"4. ì´ ë°°ì¹˜ ìˆ˜: í•™ìŠµ={len(train_loader)}ê°œ, ê²€ì¦={len(val_loader)}ê°œ")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    print(f"5. {model_type.capitalize()} ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    if model_type == 'tracer':
        model = DW_Tracer(MESSAGE_LENGTH).to(DEVICE)
        model_path = TRACER_MODEL_PATH
    else:  # detector
        model = DW_Detector(MESSAGE_LENGTH).to(DEVICE)
        model_path = DETECTOR_MODEL_PATH
    
    # ë…¸ì´ì¦ˆ ë ˆì´ì–´, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
    print("6. ë…¸ì´ì¦ˆ ë ˆì´ì–´ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™” ì¤‘...")
    noise_pool = RandomForwardNoisePool()
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))
    
    # í•™ìŠµ ê²°ê³¼ ì¶”ì 
    print("7. í•™ìŠµ ë³€ìˆ˜ ì´ˆê¸°í™” ì¤‘...")
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    best_val_loss = float('inf')
    
    print(f"\n8. í•™ìŠµ ì‹œì‘ ({EPOCHS} ì—í¬í¬)...\n")
    for epoch in range(EPOCHS):
        model.train()
        epoch_loss = 0
        epoch_accuracy = 0
        start_time = time.time()
        
        print(f"ğŸ”„ ì—í¬í¬ {epoch+1}/{EPOCHS} ì‹œì‘")
        
        for batch_idx, (encoded_imgs, original_imgs, target_msgs) in enumerate(train_loader):
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if batch_idx % 2 == 0 or batch_idx == len(train_loader) - 1:
                print(f"   ë°°ì¹˜ ì§„í–‰: {batch_idx+1}/{len(train_loader)} ({(batch_idx+1)/len(train_loader)*100:.1f}%)")
            
            encoded_imgs = encoded_imgs.to(DEVICE)
            target_msgs = target_msgs.to(DEVICE)
            
            # ë…¸ì´ì¦ˆ ì ìš© (SepMarkì˜ RFNP ì°¸ê³ )
            if model_type == 'tracer':
                # TracerëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ì™œê³¡ì— ëŒ€ì‘í•´ì•¼ í•¨
                print(f"   ë°°ì¹˜ {batch_idx+1}: ë…¸ì´ì¦ˆ ì ìš© ì¤‘...") if batch_idx % 5 == 0 else None
                noised_imgs = noise_pool.random_distortion(encoded_imgs, include_malicious=True)
            else:  # detector
                # DetectorëŠ” ì¼ë°˜ ì™œê³¡ì—ëŠ” ê°•ì¸í•˜ê³  ì•…ì˜ì  ì™œê³¡ì—ëŠ” ì·¨ì•½í•´ì•¼ í•¨
                # í•™ìŠµ ì‹œ 50% í™•ë¥ ë¡œ ì¼ë°˜/ì•…ì˜ì  ì™œê³¡ êµ¬ë¶„
                print(f"   ë°°ì¹˜ {batch_idx+1}: ë…¸ì´ì¦ˆ ì ìš© ì¤‘...") if batch_idx % 5 == 0 else None
                if torch.rand(1).item() < 0.5:
                    noised_imgs = noise_pool.random_distortion(encoded_imgs, include_malicious=False)
                    target = target_msgs  # ì¼ë°˜ ì™œê³¡: ì›ë˜ ë©”ì‹œì§€ ì¶”ì¶œ ëª©í‘œ
                else:
                    noised_imgs = noise_pool.random_distortion(encoded_imgs, include_malicious=True)
                    target = torch.zeros_like(target_msgs)  # ì•…ì˜ì  ì™œê³¡: 0ìœ¼ë¡œ ì¶”ì¶œ ëª©í‘œ (ëœë¤ ì¶”ì¸¡)
            
            # ëª¨ë¸ í†µê³¼
            print(f"   ë°°ì¹˜ {batch_idx+1}: ëª¨ë¸ í†µê³¼ ì¤‘...") if batch_idx % 5 == 0 else None
            optimizer.zero_grad()
            if model_type == 'tracer':
                extracted_msg = model(noised_imgs)
                loss = criterion(extracted_msg, target_msgs)
                accuracy = calculate_bit_accuracy(extracted_msg, target_msgs)
            else:
                extracted_msg = model(noised_imgs)
                loss = criterion(extracted_msg, target)
                accuracy = calculate_bit_accuracy(extracted_msg, target)
            
            # ì—­ì „íŒŒ ë° ì˜µí‹°ë§ˆì´ì € ìŠ¤í…
            print(f"   ë°°ì¹˜ {batch_idx+1}: ì—­ì „íŒŒ ì¤‘...") if batch_idx % 5 == 0 else None
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            epoch_accuracy += accuracy
            
            if batch_idx % 5 == 0:
                print(f"   ë°°ì¹˜ {batch_idx+1} ì™„ë£Œ: Loss={loss.item():.6f}, Acc={accuracy:.2f}%")
        
        # ì—í¬í¬ í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ê³„ì‚°
        epoch_loss /= len(train_loader)
        epoch_accuracy /= len(train_loader)
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_accuracy)
        
        # ê²€ì¦
        print(f"   ê²€ì¦ ì‹œì‘...")
        model.eval()
        val_loss = 0
        val_accuracy = 0
        
        with torch.no_grad():
            for val_idx, (encoded_imgs, original_imgs, target_msgs) in enumerate(val_loader):
                if val_idx % 2 == 0:
                    print(f"   ê²€ì¦ ë°°ì¹˜: {val_idx+1}/{len(val_loader)}")
                    
                encoded_imgs = encoded_imgs.to(DEVICE)
                target_msgs = target_msgs.to(DEVICE)
                
                # ë…¸ì´ì¦ˆ ì ìš© (í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹)
                if model_type == 'tracer':
                    noised_imgs = noise_pool.random_distortion(encoded_imgs, include_malicious=True)
                    extracted_msg = model(noised_imgs)
                    loss = criterion(extracted_msg, target_msgs)
                    accuracy = calculate_bit_accuracy(extracted_msg, target_msgs)
                else:
                    # Detector ê²€ì¦ì€ ë‘ ê°€ì§€ ê²½ìš°ë¥¼ ë²ˆê°ˆì•„ê°€ë©° ìˆ˜í–‰
                    if torch.rand(1).item() < 0.5:
                        noised_imgs = noise_pool.random_distortion(encoded_imgs, include_malicious=False)
                        target = target_msgs
                    else:
                        noised_imgs = noise_pool.random_distortion(encoded_imgs, include_malicious=True)
                        target = torch.zeros_like(target_msgs)
                    
                    extracted_msg = model(noised_imgs)
                    loss = criterion(extracted_msg, target)
                    accuracy = calculate_bit_accuracy(extracted_msg, target)
                
                val_loss += loss.item()
                val_accuracy += accuracy
        
        val_loss /= len(val_loader)
        val_accuracy /= len(val_loader)
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)
        
        # ì—í¬í¬ ì‹œê°„ ê³„ì‚°
        epoch_time = time.time() - start_time
        
        # ì¶œë ¥
        print(f"ğŸ“Š ì—í¬í¬ {epoch+1}/{EPOCHS} ì™„ë£Œ | "
              f"Train Loss: {epoch_loss:.6f} | "
              f"Val Loss: {val_loss:.6f} | "
              f"Train Acc: {epoch_accuracy:.2f}% | "
              f"Val Acc: {val_accuracy:.2f}% | "
              f"ì‹œê°„: {epoch_time:.2f}ì´ˆ")
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), model_path)
            print(f"âœ… ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ ({model_type})")
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë¸ ì €ì¥
        if (epoch + 1) % SAVE_INTERVAL == 0:
            checkpoint_path = f"./saved_models/{model_type}_epoch{epoch+1}.pth"
            torch.save(model.state_dict(), checkpoint_path)
            
    # í•™ìŠµ ê·¸ë˜í”„ ì €ì¥
    print("\nğŸ“ˆ í•™ìŠµ ê·¸ë˜í”„ ì €ì¥ ì¤‘...")
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title(f'{model_type.capitalize()} Loss')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies, label='Train Accuracy')
    plt.plot(val_accuracies, label='Val Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title(f'{model_type.capitalize()} Accuracy')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(f"{RESULTS_DIR}/{model_type}_training.png")
    plt.close()
    
    print(f"\nâœ… {model_type.capitalize()} í•™ìŠµ ì™„ë£Œ")
    return model


# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    import sys
    
    print(f"[ì‹œìŠ¤í…œ ì •ë³´] CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"[ì‹œìŠ¤í…œ ì •ë³´] GPU: {torch.cuda.get_device_name(0)}")
    
    print(f"[ì„¤ì • ì •ë³´] ë©”ì‹œì§€ ê¸¸ì´: {MESSAGE_LENGTH}")
    print(f"[ì„¤ì • ì •ë³´] ì…ë ¥ í¬ê¸°: {INPUT_RESIZE}x{INPUT_RESIZE}")
    print(f"[ì„¤ì • ì •ë³´] ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
    print(f"[ì„¤ì • ì •ë³´] ìµœëŒ€ ìƒ˜í”Œ ìˆ˜: {MAX_SAMPLES}")
    print(f"[ì„¤ì • ì •ë³´] ê³ ì • ë©”ì‹œì§€: {FIXED_MESSAGE_STR}")
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "train_tracer":
            train_decoder('tracer')
        elif command == "train_detector":
            train_decoder('detector')
        elif command == "train_all":
            print("Tracer í•™ìŠµ ì‹œì‘...")
            train_decoder('tracer')
            print("\nDetector í•™ìŠµ ì‹œì‘...")
            train_decoder('detector')
        else:
            print("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. ì‚¬ìš©ë²•:")
            print("  python Decoder_train.py train_tracer")
            print("  python Decoder_train.py train_detector")
            print("  python Decoder_train.py train_all")
    else:
        print("[SepMark ë””ì½”ë” í•™ìŠµ ì•ˆë‚´]")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:")
        print("  python Decoder_train.py train_tracer   - Tracer ëª¨ë¸ í•™ìŠµ")
        print("  python Decoder_train.py train_detector - Detector ëª¨ë¸ í•™ìŠµ")
        print("  python Decoder_train.py train_all      - ë‘ ëª¨ë¸ ëª¨ë‘ í•™ìŠµ")